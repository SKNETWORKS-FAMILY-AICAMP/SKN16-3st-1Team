import os
from dotenv import load_dotenv
import torch
from src.chat_engine.rag_pipeline import RAGPipeline
from src.ui_interface.main_ui import main_ui
from src.vector_store.chroma_client import create_chroma_client
from src.vector_store.embeddings import create_embedding_generator

from typing import cast

try:
    from langchain_community.vectorstores import Chroma
except ImportError:
    from langchain.vectorstores import Chroma

EMBEDDING_MODEL = "google/embeddinggemma-300m"


def get_device():
    # Determine best available device (MPS > CUDA > CPU)
    if torch.backends.mps.is_available():
        device = torch.device("mps")  # Mac M-series GPU
    elif torch.cuda.is_available():
        device = torch.device("cuda")  # NVIDIA GPU
    else:
        device = torch.device("cpu")   # CPU fallback
    return device

def build_rag_chain() -> RAGPipeline:
    device = get_device()

    embedding = create_embedding_generator(model_name = EMBEDDING_MODEL,
                                           device=device)
    vector_db_client = create_chroma_client(persist_directory="data/vector_db",
                                     collection_name="edu_content",
                                     embedding_function=embedding)
    if not vector_db_client.is_connected():        
        vector_db_client.connect()

    c_info = vector_db_client.get_collection_info()
    print(c_info)

    vector_db= vector_db_client.get_vectorstore()
    print(f"coll count: {len(vector_db)}")

    pipeline = RAGPipeline(
        llm_model="gpt-3.5-turbo",
        llm_temperature=0.7,
        vector_store=vector_db
    )

    # # ì§ˆë¬¸ ì²˜ë¦¬
    # result = pipeline.generate_answer(
    #     question="ë¨¸ì‹ ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë…ì€?",
    #     use_rag=True
    # )

    # print(result.answer)
    return pipeline

def excute_ui():    
    pipeline = build_rag_chain()
    main_ui(pipeline)


def initialize_vector_db(force_rebuild=False, forDevel=False):
    """ë²¡í„° DB ì´ˆê¸°í™”"""
    import os
    import glob
    from pathlib import Path
    from src.document_processor.core import DocumentProcessorFactory


    print("ğŸš€ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘...")

    try:
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = get_device()
        print(f"ğŸ“± ë””ë°”ì´ìŠ¤: {device}")

        # LangChain í˜¸í™˜ ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        embedding = create_embedding_generator(model_name = EMBEDDING_MODEL,
                                        device=str(device))

        # ë²¡í„° DB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        vector_db_client = create_chroma_client(
            persist_directory="data/vector_db",
            collection_name="edu_content",
            embedding_function=embedding
        )

        # ì—°ê²°
        if not vector_db_client.connect():
            print("âŒ ë²¡í„° DB ì—°ê²° ì‹¤íŒ¨")
            return False

        # ê°•ì œ ì¬êµ¬ì¶•ì¸ ê²½ìš° ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        if force_rebuild:
            print("ğŸ”„ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì¬ì„¤ì •...")
            if not vector_db_client.reset_collection():
                print("âŒ ì»¬ë ‰ì…˜ ì¬ì„¤ì • ì‹¤íŒ¨")
                return False

        # êµìœ¡ ìë£Œ ë””ë ‰í† ë¦¬ ì„¤ì •
        materials_dir = Path("data/educational_materials")
        pdf_dir = materials_dir / "pdfs"
        notebook_dir = materials_dir / "notebooks"

        if forDevel: # ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ì§‘ (PDFëŠ” 5ê°œë§Œ, ë…¸íŠ¸ë¶ë„ 20ê°œë§Œ)
            pdf_files = list(glob.glob(str(pdf_dir / "*.pdf")))[:5] if pdf_dir.exists() else []
            notebook_files = list(glob.glob(str(notebook_dir / "*.ipynb")))[:20] if notebook_dir.exists() else []
        else:
            pdf_files = list(glob.glob(str(pdf_dir / "*.pdf"))) if pdf_dir.exists() else []
            notebook_files = list(glob.glob(str(notebook_dir / "*.ipynb"))) if notebook_dir.exists() else []
        all_files = pdf_files + notebook_files
        total_files = len(all_files)

        if total_files == 0:
            print("âš ï¸ ì²˜ë¦¬í•  êµìœ¡ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        print(f"ğŸ“„ ì´ {total_files}ê°œ íŒŒì¼ ì²˜ë¦¬ ì˜ˆì •:")
        print(f"   - PDF: {len(pdf_files)}ê°œ")
        print(f"   - Notebook: {len(notebook_files)}ê°œ")
        print("="*50)

        # ë²¡í„°ìŠ¤í† ì–´ ê°€ì ¸ì˜¤ê¸°
        vectorstore = vector_db_client.get_vectorstore()
        if vectorstore == None:
            print("Vector store ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
            return False
        vectorstore = cast(Chroma, vectorstore)
        
        processed_count = 0
        failed_count = 0
        total_chunks = 0

        # ê° íŒŒì¼ ì²˜ë¦¬
        for file_path in all_files:
            file_name = Path(file_path).name
            print(f"ğŸ“– ì²˜ë¦¬ ì¤‘: {file_name}")

            try:
                # ì ì ˆí•œ í”„ë¡œì„¸ì„œ ìƒì„±
                processor = DocumentProcessorFactory.create_processor(file_path)

                # íŒŒì¼ ì²˜ë¦¬
                result = processor.process_file(file_path)

                if result.success:
                    chunks = result.chunks
                    chunk_count = len(chunks)

                    if chunk_count > 0:
                        # ì²­í¬ë“¤ì„ ë²¡í„° DBì— ì¶”ê°€
                        texts = [chunk.content for chunk in chunks]
                        metadatas = [chunk.metadata for chunk in chunks]
                        ids = [f"{file_name}_{chunk.source_location}" for chunk in chunks]

                        # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
                        vectorstore.add_texts(
                            texts=texts,
                            metadatas=metadatas,
                            ids=ids
                        )

                        processed_count += 1
                        total_chunks += chunk_count
                        print(f"   âœ… ì„±ê³µ: {chunk_count}ê°œ ì²­í¬ ìƒì„±")
                    else:
                        print(f"   âš ï¸ ê²½ê³ : ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                        failed_count += 1
                else:
                    print(f"   âŒ ì‹¤íŒ¨: {result.error_message}")
                    failed_count += 1

            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜: {str(e)}")
                failed_count += 1

        # ë²¡í„°ìŠ¤í† ì–´ ì €ì¥
        vectorstore.persist()

        # ê²°ê³¼ ì¶œë ¥
        print("="*50)
        print(f"ğŸ¯ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   - ì„±ê³µ: {processed_count}ê°œ íŒŒì¼")
        print(f"   - ì‹¤íŒ¨: {failed_count}ê°œ íŒŒì¼")
        print(f"   - ì´ ì²­í¬: {total_chunks}ê°œ")

        # ì—°ê²° í•´ì œ
        vector_db_client.disconnect()

        return processed_count > 0

    except Exception as e:
        print(f"âŒ ë²¡í„° DB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return False

load_dotenv()

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ê³ ë“±í•™ìƒ í•™ê³¼ ì„ íƒ ë„ìš°ë¯¸ - í™˜ê²½ ì„¤ì •")
    parser.add_argument("--init-db", action="store_true", 
                       help="ë²¡í„° DB ì´ˆê¸°í™”ë§Œ ì‹¤í–‰")
    parser.add_argument("--force-rebuild", action="store_true",
                       help="ê¸°ì¡´ DB ì‚­ì œ í›„ ê°•ì œ ì¬êµ¬ì¶•")
    parser.add_argument("--setup-only", action="store_true",
                       help="DB ì´ˆê¸°í™” ì—†ì´ í™˜ê²½ ì„¤ì •ë§Œ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    print("=" * 60)
    
    # DB ì´ˆê¸°í™”ë§Œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°
    if args.init_db:
        print("ğŸš€ ë²¡í„° DB ì´ˆê¸°í™” ëª¨ë“œ")
        print("-" * 40)
                    
        # ë²¡í„° DB ì´ˆê¸°í™” ì‹¤í–‰
        success = initialize_vector_db(force_rebuild=args.force_rebuild, forDevel=True)
        
        if success:
            print("\nğŸ‰ ë²¡í„° DB ì´ˆê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("\nâŒ ë²¡í„° DB ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
        return True

    excute_ui()
    
if __name__ == "__main__":
    main()